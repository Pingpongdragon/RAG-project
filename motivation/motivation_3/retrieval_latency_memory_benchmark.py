"""
Motivation 3: Naive KB Scaling Cost Benchmark
æµ‹é‡ KB è§„æ¨¡å¢é•¿å¯¹æ£€ç´¢å»¶è¿Ÿå’Œå†…å­˜çš„çº¿æ€§å½±å“

è¾“å‡º: fig_kb_size_vs_latency_memory.png
"""
import sys
import time
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from plot_config import setup_style, COLORS, save_fig

OUT_DIR = Path(__file__).resolve().parent


def benchmark_retrieval_overhead():
    """åŸºå‡†æµ‹è¯•: KBè§„æ¨¡ vs æ£€ç´¢å¼€é”€"""
    setup_style()

    print("ğŸ“Š Motivation 3: Naive Scaling Cost Benchmark")
    print("=" * 70)

    EMBED_DIM = 384
    KB_SIZES = [1_000, 5_000, 10_000, 20_000, 50_000, 100_000]
    NUM_QUERIES = 200
    TOP_K = 10

    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_vecs = np.random.randn(NUM_QUERIES, EMBED_DIM).astype(np.float32)
    query_vecs /= np.linalg.norm(query_vecs, axis=1, keepdims=True)

    results = []
    for kb_size in KB_SIZES:
        print(f"  Testing KB size: {kb_size:,} documents...")

        # ç”Ÿæˆ KB å‘é‡
        kb_vecs = np.random.randn(kb_size, EMBED_DIM).astype(np.float32)
        kb_vecs /= np.linalg.norm(kb_vecs, axis=1, keepdims=True)

        # å†…å­˜å ç”¨ (MB)
        mem_mb = kb_vecs.nbytes / (1024 * 1024)

        # Warmup (æ¶ˆé™¤ç¼“å­˜å†·å¯åŠ¨å½±å“)
        for i in range(min(20, NUM_QUERIES)):
            sims = kb_vecs @ query_vecs[i]
            _ = np.argpartition(sims, -TOP_K)[-TOP_K:]

        # å»¶è¿Ÿæµ‹é‡
        latencies_ms = []
        for i in range(NUM_QUERIES):
            t_start = time.perf_counter()
            sims = kb_vecs @ query_vecs[i]
            _ = np.argpartition(sims, -TOP_K)[-TOP_K:]
            t_end = time.perf_counter()
            latencies_ms.append((t_end - t_start) * 1000)

        avg_latency = np.mean(latencies_ms)
        p99_latency = np.percentile(latencies_ms, 99)

        results.append({
            "kb_size": kb_size,
            "avg_latency_ms": avg_latency,
            "p99_latency_ms": p99_latency,
            "memory_mb": mem_mb,
        })
        print(f"    â””â”€ Avg: {avg_latency:.2f}ms | P99: {p99_latency:.2f}ms | Memory: {mem_mb:.1f}MB")
        del kb_vecs

    return results


def plot_scaling_cost(results):
    """ç»˜åˆ¶: KBè§„æ¨¡ vs å»¶è¿Ÿ/å†…å­˜"""
    sizes_k = [r["kb_size"] / 1000 for r in results]
    avg_lats = [r["avg_latency_ms"] for r in results]
    p99_lats = [r["p99_latency_ms"] for r in results]
    memories = [r["memory_mb"] for r in results]

    fig, (ax_latency, ax_memory) = plt.subplots(1, 2, figsize=(14, 6.2))  # å¢åŠ é«˜åº¦

    # ========== å·¦å›¾: å»¶è¿Ÿ vs KBè§„æ¨¡ ==========
    ax_latency.plot(sizes_k, avg_lats, 'o-', color=COLORS['primary'], 
                    linewidth=2.5, markersize=9, markeredgecolor='white', 
                    markeredgewidth=1.5, label='Avg Latency (mean)', zorder=5)
    ax_latency.plot(sizes_k, p99_lats, 's--', color=COLORS['accent2'], 
                    linewidth=2, markersize=7, alpha=0.7, 
                    label='P99 Latency (99th percentile)', zorder=4)
    ax_latency.fill_between(sizes_k, avg_lats, alpha=0.06, color=COLORS['primary'])

    # æ ‡æ³¨æ•°å€¼ (ä¿®å¤: æ·»åŠ  ms å•ä½)
    for x, y in zip(sizes_k, avg_lats):
        ax_latency.text(x, y + max(avg_lats) * 0.04, f"{y:.1f}ms", 
                        ha='center', fontsize=9, fontweight='bold', 
                        color=COLORS['primary'])
    
    # æ ‡æ³¨æ•°å€¼ (P99 Latency) - æ–°å¢
    for x, y in zip(sizes_k, p99_lats):
        ax_latency.text(x, y + max(p99_lats) * 0.04, f"{y:.1f}ms", 
                        ha='center', fontsize=9, fontweight='bold', 
                        color=COLORS['accent2'])

    # å¢é•¿å€æ•°æ ‡æ³¨
    speedup = avg_lats[-1] / avg_lats[0]
    ax_latency.annotate(
        f'{speedup:.1f}Ã— slower',
        xy=(sizes_k[-1], avg_lats[-1]),
        xytext=(sizes_k[-1] - 20, avg_lats[-1] * 0.6),
        fontsize=12, fontweight='bold', color=COLORS['secondary'],
        arrowprops=dict(arrowstyle='->', color=COLORS['secondary'], lw=1.5),
        bbox=dict(boxstyle='round,pad=0.3', facecolor=COLORS['light_red'],
                  edgecolor=COLORS['secondary'], alpha=0.9),
    )

    ax_latency.set_xlabel("KB Size (Ã—1K documents)", fontsize=13)
    ax_latency.set_ylabel("Retrieval Latency (ms/query)", fontsize=13)
    ax_latency.set_title("(a) Retrieval Latency vs KB Size", fontsize=14, fontweight='bold')
    ax_latency.legend(fontsize=10, loc='upper left')
    ax_latency.set_ylim(bottom=0)
    ax_latency.grid(True, alpha=0.3)

    # ========== å³å›¾: å†…å­˜ vs KBè§„æ¨¡ ==========
    ax_memory.plot(sizes_k, memories, 's-', color=COLORS['secondary'], 
                   linewidth=2.5, markersize=9, markeredgecolor='white', 
                   markeredgewidth=1.5, zorder=5)
    ax_memory.fill_between(sizes_k, memories, alpha=0.06, color=COLORS['secondary'])

    # æ ‡æ³¨æ•°å€¼ (ä¿®å¤: æ·»åŠ  MB å•ä½)
    for x, y in zip(sizes_k, memories):
        label = f"{y:.0f}MB" if y >= 1 else f"{y:.1f}MB"
        ax_memory.text(x, y + max(memories) * 0.04, label, 
                       ha='center', fontsize=9, fontweight='bold', 
                       color=COLORS['secondary'])

    # å†…å­˜å¢é•¿å€æ•°
    mem_growth = memories[-1] / memories[0]
    ax_memory.annotate(
        f'{mem_growth:.0f}Ã— memory',
        xy=(sizes_k[-1], memories[-1]),
        xytext=(sizes_k[-1] - 25, memories[-1] * 0.5),
        fontsize=12, fontweight='bold', color=COLORS['accent2'],
        arrowprops=dict(arrowstyle='->', color=COLORS['accent2'], lw=1.5),
        bbox=dict(boxstyle='round,pad=0.3', facecolor=COLORS['light_yellow'],
                  edgecolor=COLORS['accent2'], alpha=0.9),
    )

    ax_memory.set_xlabel("KB Size (Ã—1K documents)", fontsize=13)
    ax_memory.set_ylabel("Memory Usage (MB)", fontsize=13)
    ax_memory.set_title("(b) Memory Footprint vs KB Size", fontsize=14, fontweight='bold')
    ax_memory.set_ylim(bottom=0)
    ax_memory.grid(True, alpha=0.3)

    # ========== åº•éƒ¨è­¦å‘Šæ–‡æœ¬ (ä¿®å¤ä½ç½®) ==========
    fig.text(0.5, 0.01,  # ä» -0.02 æ”¹ä¸º 0.01
             "WARNING: Naive scaling is unsustainable -> Need drift-aware selective updates",
             ha='center', fontsize=10, fontstyle='italic', color=COLORS['gray'],
             bbox=dict(boxstyle='round,pad=0.4', facecolor='#F9FAFB',
                       edgecolor=COLORS['gray'], alpha=0.8))

    # è°ƒæ•´å¸ƒå±€ (ç»™åº•éƒ¨æ–‡æœ¬ç•™å‡ºç©ºé—´)
    fig.tight_layout(rect=[0, 0.06, 1, 1])  # åº•éƒ¨ä» 0.04 æ”¹ä¸º 0.06
    
    # ä¿å­˜å›¾ç‰‡
    out_path = OUT_DIR / "fig_kb_size_vs_latency_memory.png"
    save_fig(fig, str(out_path))
    plt.close()


if __name__ == "__main__":
    np.random.seed(42)
    results = benchmark_retrieval_overhead()
    plot_scaling_cost(results)
    print("\nâœ… Motivation 3 å®éªŒå®Œæˆ!")
    print(f"ğŸ“Š å›¾ç‰‡å·²ä¿å­˜è‡³: {OUT_DIR / 'fig_kb_size_vs_latency_memory.png'}")