import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import random
from tqdm import tqdm
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.metrics.pairwise import cosine_similarity

try:
    from river import drift
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… river: pip install river")
    sys.exit(1)

# ================= 1. æ„é€ åˆæˆæ•°æ® =================
def generate_synthetic_data():
    print("ğŸ§ª æ­£åœ¨æ„é€ åˆæˆæ•°æ® (Synthetic Data)...")
    
    # å®šä¹‰ä¸¤ç»„å®Œå…¨ä¸ç›¸äº¤çš„è¯æ±‡
    vocab_a = [f"sport_word_{i}" for i in range(50)] # æ¨¡æ‹Ÿä½“è‚²è¯æ±‡
    vocab_b = [f"biz_word_{i}" for i in range(50)]   # æ¨¡æ‹Ÿå•†ä¸šè¯æ±‡
    
    def generate_docs(vocab, count, min_len=10, max_len=20):
        docs = []
        for _ in range(count):
            # éšæœºç”Ÿæˆå¥å­
            length = random.randint(min_len, max_len)
            words = random.choices(vocab, k=length)
            docs.append(" ".join(words))
        return docs

    # 1. è®­ç»ƒé›†ï¼šæ··åˆ A å’Œ Bï¼Œè®© LDA å­¦ä¼šè¿™ä¸¤ç§æ¨¡å¼
    train_a = generate_docs(vocab_a, 2000)
    train_b = generate_docs(vocab_b, 2000)
    train_corpus = train_a + train_b
    random.shuffle(train_corpus) # æ‰“ä¹±ç”¨äºè®­ç»ƒ
    
    # 2. éªŒè¯é›†ï¼šç”¨äºè®¡ç®— Topic A çš„ä¸­å¿ƒç‚¹
    # æˆ‘ä»¬å¸Œæœ›ç³»ç»Ÿè®¤ä¸º A æ˜¯"æ­£å¸¸"çš„
    validation_source = generate_docs(vocab_a, 500)
    
    # 3. æ•°æ®æµï¼šA -> B -> A
    stream_normal_1 = generate_docs(vocab_a, 200)
    stream_shift = generate_docs(vocab_b, 200)
    stream_normal_2 = generate_docs(vocab_a, 200)
    
    return train_corpus, validation_source, stream_normal_1, stream_shift, stream_normal_2

# ================= 2. è®­ç»ƒä¸åŸºå‡†å»ºç«‹ =================
def train_and_get_centroid(train_docs, source_docs):
    print("âš™ï¸ Training LDA on Synthetic Corpus...")
    
    # è¯è¡¨æ˜¯å›ºå®šçš„ï¼Œä¸éœ€è¦è¿‡æ»¤
    vectorizer = CountVectorizer()
    tf_train = vectorizer.fit_transform(train_docs)
    
    # è®­ç»ƒ LDAï¼Œå¼ºè¡Œè®©å®ƒæŠŠè¯æ±‡åˆ†æˆ 5 ç±» (å“ªæ€•æˆ‘ä»¬åªæœ‰2ç±»çœŸå€¼ï¼Œæ¨¡æ‹ŸçœŸå®æƒ…å†µ)
    lda = LatentDirichletAllocation(n_components=5, random_state=42)
    lda.fit(tf_train)
    
    print("âš™ï¸ Calculating Source Topic Centroid...")
    # è®¡ç®— Source (Topic A) çš„ä¸­å¿ƒç‚¹
    tf_source = vectorizer.transform(source_docs)
    topic_dist_source = lda.transform(tf_source)
    source_centroid = np.mean(topic_dist_source, axis=0).reshape(1, -1)
    
    return lda, vectorizer, source_centroid

# ================= 3. è¿è¡Œæµ =================
def run_experiment():
    # 1. è·å–æ•°æ®
    train, val_src, stream_1, stream_2, stream_3 = generate_synthetic_data()
    
    # 2. è®­ç»ƒæ¨¡å‹
    lda, vec, centroid = train_and_get_centroid(train, val_src)
    
    # 3. æ„é€ æµ
    full_stream = stream_1 + stream_2 + stream_3
    labels = ["Normal (A)"]*200 + ["Shift (B)"]*200 + ["Return (A)"]*200
    
    # 4. ADWIN ç›‘æ§
    adwin = drift.ADWIN(delta=0.002)
    
    scores = []
    means = []
    drifts = []
    
    print("\nğŸš€ Running Synthetic Stream...")
    for i, text in enumerate(tqdm(full_stream)):
        # è½¬æ¢
        tf = vec.transform([text])
        topic_dist = lda.transform(tf)
        
        # è®¡ç®—ç›¸ä¼¼åº¦ (0~1)
        sim = cosine_similarity(topic_dist, centroid)[0][0]
        
        # æ›´æ–°ç›‘æ§
        adwin.update(sim)
        
        scores.append(sim)
        means.append(adwin.estimation)
        
        if adwin.drift_detected:
            drifts.append(i)
            
    return scores, means, drifts, labels

# ================= 4. ç»˜å›¾ =================
def plot_results(scores, means, drifts, labels):
    fig, ax = plt.subplots(figsize=(12, 6))
    x = range(len(scores))
    
    # æ•£ç‚¹
    ax.scatter(x, scores, s=10, color='gray', alpha=0.3, label='Raw Similarity')
    # å‡å€¼çº¿
    ax.plot(x, means, color='blue', linewidth=3, label='ADWIN Mean')
    
    # é˜¶æ®µèƒŒæ™¯
    ax.axvspan(0, 200, color='green', alpha=0.1, label='Phase 1: Normal')
    ax.axvspan(200, 400, color='red', alpha=0.1, label='Phase 2: Shift')
    ax.axvspan(400, 600, color='green', alpha=0.1, label='Phase 3: Return')
    
    # æ¼‚ç§»çº¿
    for d in drifts:
        ax.axvline(x=d, color='red', linestyle='--', linewidth=2)
        
    ax.set_title('Ideally Separated Data Shift Detection (LDA + ADWIN)', fontsize=14)
    ax.set_ylabel('Similarity to Source Topic', fontsize=12)
    ax.set_ylim(-0.1, 1.1)
    ax.legend(loc='lower left')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('synthetic_shift.png', dpi=300)
    print("\nâœ… Plot Saved: synthetic_shift.png")

if __name__ == "__main__":
    s, m, d, l = run_experiment()
    plot_results(s, m, d, l)