import os
import zipfile
import requests
from pathlib import Path
from tqdm import tqdm

# ================= é…ç½® =================
DATA_ROOT = Path("./data")
RAW_DATA_DIR = DATA_ROOT / "raw_data"
DATASET_NAME = "fiqa"
URL = f"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{DATASET_NAME}.zip"

def download_and_unzip():
    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)
    zip_path = RAW_DATA_DIR / f"{DATASET_NAME}.zip"
    extract_path = RAW_DATA_DIR / DATASET_NAME

    # 1. ä¸‹è½½
    if not zip_path.exists():
        print(f"ğŸš€ æ­£åœ¨ä¸‹è½½ {DATASET_NAME} æ•°æ®é›† (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
        response = requests.get(URL, stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        with open(zip_path, 'wb') as file, tqdm(
            desc=DATASET_NAME,
            total=total_size,
            unit='iB',
            unit_scale=True,
            unit_divisor=1024,
        ) as bar:
            for data in response.iter_content(chunk_size=1024):
                size = file.write(data)
                bar.update(size)
    else:
        print(f"ğŸ“¦ å‹ç¼©åŒ…å·²å­˜åœ¨: {zip_path}")

    # 2. è§£å‹
    if not extract_path.exists():
        print("ğŸ“‚ æ­£åœ¨è§£å‹...")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(RAW_DATA_DIR)
        print(f"âœ… è§£å‹å®Œæˆ: {extract_path}")
    else:
        print(f"âœ… æ•°æ®ç›®å½•å·²å‡†å¤‡å¥½: {extract_path}")

from huggingface_hub import snapshot_download
from transformers import AutoTokenizer, AutoModelForSequenceClassification

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"


MODEL_NAME = "BAAI/bge-reranker-base"

def download_model():
    print(f"\nğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {MODEL_NAME}")
    print(f"   é•œåƒæº: {os.environ.get('HF_ENDPOINT')}")
    
    try:
        # 1. ä½¿ç”¨ snapshot_download ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°ç¼“å­˜
        path = snapshot_download(
            repo_id=MODEL_NAME,
            resume_download=True,
            local_files_only=False
        )
        print(f"âœ… æ¨¡å‹æ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œå­˜å‚¨è·¯å¾„: {path}")
        
        # 2. å°è¯•åŠ è½½ä¸€æ¬¡ï¼Œç¡®ä¿æ–‡ä»¶å®Œæ•´å¯ç”¨
        print("ğŸ”„ æ­£åœ¨å°è¯•åŠ è½½æ¨¡å‹ä»¥éªŒè¯å®Œæ•´æ€§...")
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
        
        print(f"ğŸ‰ éªŒè¯æˆåŠŸï¼æ¨¡å‹å·²å‡†å¤‡å°±ç»ªã€‚")
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½æˆ–åŠ è½½å¤±è´¥: {str(e)}")
        print("å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚")



if __name__ == "__main__":
    download_model()