import json
import random
import time
import os
from typing import List, Dict, Any
from tqdm import tqdm
from datasets import load_dataset

# ==========================================
# 0. Google GenAI Setup
# ==========================================
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# è¯»å–çŽ¯å¢ƒå˜é‡ (ä½ åœ¨ CMD ä¸­ export çš„é‚£äº›)
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise ValueError("è¯·å…ˆè®¾ç½® GOOGLE_API_KEY çŽ¯å¢ƒå˜é‡ï¼")

# é…ç½® Google GenAI
genai.configure(api_key=GOOGLE_API_KEY)

# ==========================================
# 1. Configuration & Constants
# ==========================================

# æŽ¨èä½¿ç”¨ gemini-1.5-flash (é€Ÿåº¦å¿«ã€ä¾¿å®œã€é€‚åˆæ ‡æ³¨) æˆ– gemini-1.5-pro (æ›´å¼º)
MODEL_NAME = "gemini-1.5-flash" 

# âš ï¸ å¿…é¡»ä¸Ž Student æ¨¡åž‹è®­ç»ƒæ—¶çš„é¡ºåºå®Œå…¨ä¸€è‡´ï¼
DOMAIN_LABELS = ["entertainment", "stem", "humanities", "lifestyle"]

# System Prompt
SYSTEM_PROMPT = """You are an advanced data annotator for a RAG router. 
Your task is to classify user queries into specific knowledge domains.
You must output the result in a strict JSON format."""

USER_PROMPT_TEMPLATE = """
Analyze the following user query and determine the probability distribution across these 4 domains:

1. **Entertainment**: Movies, music, celebrities, video games, comics, fictional books.
2. **STEM**: Science, technology, engineering, mathematics, physics, biology, computer science, software.
3. **Humanities**: History, politics, philosophy, religion, literature, art, social studies, war.
4. **Lifestyle**: Sports, food/cooking, travel, fashion, cars/vehicles, pets, hobbies, health/fitness.

**Input Query:** "{query}"

**Instructions:**
1. Assign a probability (float between 0.0 and 1.0) to each domain.
2. The sum of all probabilities **must equal 1.0**.
3. **Capture Uncertainty**: If the query is ambiguous (e.g., "Sci-Fi Movie History"), distribute probabilities (e.g., [0.45, 0.05, 0.45, 0.05]).
4. Output strictly in the following JSON format:

{{
    "probabilities": [P_entertainment, P_stem, P_humanities, P_lifestyle],
    "reasoning": "A short explanation in English"
}}
"""

# ==========================================
# 2. Data Loading (HotpotQA + WoW)
# ==========================================
# (è¿™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜ï¼Œä¸ºäº†å®Œæ•´æ€§æˆ‘ä¿ç•™åœ¨è¿™é‡Œ)

def load_mixed_data(sample_size=200):
    queries = []
    print("ðŸ“¥ Loading HotpotQA (questions)...")
    try:
        ds_hotpot = load_dataset("hotpot_qa", "distractor", split="train", streaming=True)
        iterator = iter(ds_hotpot)
        for _ in range(sample_size // 2):
            item = next(iterator)
            queries.append({"text": item['question'], "source": "hotpot_qa"})
    except Exception as e:
        print(f"âš ï¸ Failed to load HotpotQA: {e}")

    print("ðŸ“¥ Loading Wizard of Wikipedia (dialogues)...")
    try:
        ds_wow = load_dataset("chujiezheng/wizard_of_wikipedia", split="train", streaming=True)
        iterator = iter(ds_wow)
        for _ in range(sample_size // 2):
            item = next(iterator)
            topic = item.get("chosen_topic", "")
            first_msg = ""
            history = item.get("history", [])
            if not history and 'dialog' in item:
                 history = item['dialog']
            if history and len(history) > 0:
                first_msg = history[0].get("text", "") if isinstance(history[0], dict) else history[0]

            query_text = first_msg if (first_msg and len(first_msg) > 10 and random.random() > 0.3) else f"Tell me about {topic}"
            queries.append({"text": query_text, "source": "wow"})
    except Exception as e:
        print(f"âš ï¸ Failed to load WoW: {e}")

    random.shuffle(queries)
    print(f"âœ… Total queries prepared: {len(queries)}")
    return queries

# ==========================================
# 3. LLM Annotator (Google Gemini Implementation)
# ==========================================

class LLMLabeler:
    def __init__(self):
        # åˆå§‹åŒ–æ¨¡åž‹
        # generation_config ç”¨äºŽå¼ºåˆ¶ JSON è¾“å‡º
        self.model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            system_instruction=SYSTEM_PROMPT,
            generation_config={"response_mime_type": "application/json"}
        )
        
        # å®‰å…¨è®¾ç½®ï¼šå…³æŽ‰å®‰å…¨è¿‡æ»¤ï¼Œé˜²æ­¢è¯¯æ€æ™®é€š Query
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

    def annotate(self, text):
        prompt = USER_PROMPT_TEMPLATE.format(query=text)
        
        for attempt in range(3):
            try:
                # è°ƒç”¨ Gemini API
                response = self.model.generate_content(
                    prompt, 
                    safety_settings=self.safety_settings
                )
                
                # è§£æž JSON
                data = json.loads(response.text)
                probs = data.get("probabilities")
                
                # éªŒè¯æ•°æ®
                if not probs or len(probs) != 4:
                    continue
                
                # å½’ä¸€åŒ–
                total = sum(probs)
                if total == 0: continue
                norm_probs = [float(p)/total for p in probs]
                
                # ç¡®å®š Hard Label
                hard_label_idx = norm_probs.index(max(norm_probs))
                
                return {
                    "text": text,
                    "teacher_probs": norm_probs,
                    "hard_label": hard_label_idx,
                    "label_name": DOMAIN_LABELS[hard_label_idx],
                    "reasoning": data.get("reasoning", "")
                }
                
            except Exception as e:
                # print(f"Error: {e}") # è°ƒè¯•æ—¶æ‰“å¼€
                time.sleep(1) # é‡åˆ° Rate Limit ç­‰å¾…ä¸€ä¸‹
        return None

# ==========================================
# 4. Main Execution
# ==========================================

def main():
    OUTPUT_FILE = "train_distill_mixed_gemini.jsonl"
    
    # èŽ·å–æ•°æ® (ç¤ºä¾‹å– 20 æ¡ï¼Œä½ å¯ä»¥æ”¹å¤§)
    raw_data = load_mixed_data(sample_size=20) 
    
    labeler = LLMLabeler()
    
    print(f"ðŸš€ Starting annotation using Google {MODEL_NAME}...")
    
    valid_count = 0
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for item in tqdm(raw_data):
            text = item["text"]
            result = labeler.annotate(text)
            
            if result:
                result["dataset_source"] = item["source"]
                f.write(json.dumps(result, ensure_ascii=False) + "\n")
                valid_count += 1
    
    print(f"\nâœ… Annotation complete! {valid_count}/{len(raw_data)} samples saved to {OUTPUT_FILE}")
    if valid_count > 0:
        print("Sample output:")
        with open(OUTPUT_FILE, "r") as f:
            print(f.readline())

if __name__ == "__main__":
    main()